{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQ8/wR7QjL1/s29Iz829us",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MrYousaf128/Machine-Learning/blob/main/Food_Classification_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "Y8yqpFQ6FirN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide the path of the test, train, and val folder, which contains food images. This folder is present in the given dataset."
      ],
      "metadata": {
        "id": "VGpOKuIbIhW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test= \"/content/evaluation/\"\n",
        "val = \"/content/validation/\"\n",
        "train = \"/content/training/\""
      ],
      "metadata": {
        "id": "GQiORklAFjSX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 16\n",
        "seeds = 41\n",
        "img_shape = (250,250)"
      ],
      "metadata": {
        "id": "Td--u94XGXvd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
        "data_generator = ImageDataGenerator(\n",
        "        preprocessing_function=preprocess_input,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        validation_split=0.25,\n",
        "        rotation_range=45,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')"
      ],
      "metadata": {
        "id": "n8SJGGpBGbsf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_data_generator = ImageDataGenerator(preprocessing_function=preprocess_input,validation_split=0.25)\n",
        "\n",
        "test_generator = ImageDataGenerator(preprocessing_function=preprocess_input)"
      ],
      "metadata": {
        "id": "JxAu_6d3GeHb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = data_generator.flow_from_directory(train, target_size=img_shape, shuffle=True, seed=seeds,\n",
        "                                                     class_mode='categorical', batch_size=BATCH_SIZE, subset=\"training\")\n",
        "\n",
        "validation_generator = val_data_generator.flow_from_directory(train, target_size=img_shape, shuffle=False, seed=seeds,\n",
        "                                                     class_mode='categorical', batch_size=BATCH_SIZE, subset=\"validation\")\n",
        "\n",
        "\n",
        "test_generator = test_generator.flow_from_directory(test, target_size=img_shape, shuffle=False, seed=seeds,\n",
        "                                                     class_mode='categorical', batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "tjSFrKDdGjsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_train_samples = train_generator.samples\n",
        "nb_validation_samples = validation_generator.samples\n",
        "nb_test_samples = test_generator.samples\n",
        "classes = list(train_generator.class_indices.keys())\n",
        "print('Classes:- '+str(classes))\n",
        "total_classes  = len(classes)\n",
        "print('Number of Classes :- '+str(total_classes))"
      ],
      "metadata": {
        "id": "ow5VsBcPGuEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random_images = []\n",
        "for _ in range(4):\n",
        "    batch = next(train_generator)\n",
        "    image = batch[0][0]\n",
        "    random_images.append(image)\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(4):\n",
        "    plt.subplot(2, 2, i+1)\n",
        "    plt.imshow(random_images[i])\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1HVs0BcLGzK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(img_shape[0], img_shape[1], 3))\n",
        "\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(100, activation='relu')(x)\n",
        "predictions = Dense(total_classes, activation='softmax', kernel_initializer='random_uniform')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable=False\n",
        "\n",
        "optimizer = Adam()\n",
        "model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "QL6xEAjiG1pj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 15\n",
        "\n",
        "callbacks_list = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath='model.h5',\n",
        "        monitor='val_loss', save_best_only=True, verbose=1),\n",
        "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=6, verbose=1)\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // BATCH_SIZE,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks_list,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=nb_validation_samples // BATCH_SIZE,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "3SlxEh9eG3gL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_dict = history.history\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "epochs_x = range(1, len(loss_values) + 1)"
      ],
      "metadata": {
        "id": "NX9jAlA2G3WZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(epochs_x, loss_values, 'bo', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss_values, 'b', label='Validation loss')\n",
        "plt.title('Loss and Accuracy of Training and Validation')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.subplot(2,1,2)\n",
        "acc_values = history_dict['accuracy']\n",
        "val_acc_values = history_dict['val_accuracy']\n",
        "plt.plot(epochs_x, acc_values, 'bo', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc_values, 'r', label='Validation acc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Acc')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qQOfIVcRG3Oq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "val_accuracy = list()\n",
        "val_loss = list()\n",
        "test_loss= list()\n",
        "test_accuracy = list()\n",
        "model = load_model('/content/model.h5')"
      ],
      "metadata": {
        "id": "1bQI1SgcG2xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate_generator(validation_generator)\n",
        "val_loss.append(score[0])\n",
        "val_accuracy.append(score[1])\n",
        "print('Validation loss:', score[0])\n",
        "print('Validation accuracy:', score[1])\n",
        "score = model.evaluate_generator(test_generator)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "test_loss.append(score[0])\n",
        "test_accuracy.append(score[1])"
      ],
      "metadata": {
        "id": "4txbO2IiHA1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "img_path = '/content/validation/Dairy product/10.jpg'\n",
        "img = image.load_img(img_path, target_size=img_shape)\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "predictions = model.predict(x)\n",
        "class_index = np.argmax(predictions)\n",
        "predicted_class = classes[class_index]\n",
        "print('Predicted class:', predicted_class)"
      ],
      "metadata": {
        "id": "pu0iYFfeHE3K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}